{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pdfminer.six\n",
    "# !pip install spacy \n",
    "# !python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy,re,glob\n",
    "import pdfminer.high_level as pdfhl\n",
    "import pdfminer.layout as pdflo\n",
    "import pandas as pd\n",
    "\n",
    "# 设置extract_text()的参数，未设置部分单词会存在没有空格的情况\n",
    "laparams = pdflo.LAParams()\n",
    "setattr(laparams, 'all_texts', True)\n",
    "# 导入data目录下的所有pdf\n",
    "pdfs = glob.glob(\"data/*.pdf\")\n",
    "text = \"\"\n",
    "for pdf in pdfs:\n",
    "    temp = pdfhl.extract_text(pdf, laparams=laparams).lower()\n",
    "    # 将无意义的字符（数字、特殊符号、缩写等）替换成空格\n",
    "    temp = re.sub(r\"burningvocabulary\\.com|’ll|n’t|’s|’re|[^a-zA-Z]+\",' ',temp)\n",
    "    text += temp\n",
    "\n",
    "\n",
    "# 通过Spacy 还原单词原型，并统计单词的出现频次\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# 默认的nlp处理的文本大小1000000,报错的话 把max_length设置大一点\n",
    "nlp.max_length = 2000000\n",
    "doc = nlp(text)\n",
    "dicts = {}\n",
    "for token in doc:\n",
    "    # 只统计字母数大于2的单词\n",
    "    if len(token.lemma_) > 2:\n",
    "        dicts[token.lemma_] = dicts.get(token.lemma_,0)+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>8279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>and</td>\n",
       "      <td>3039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>that</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>have</td>\n",
       "      <td>1448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for</td>\n",
       "      <td>1403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3522</th>\n",
       "      <td>bloodstream</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6594</th>\n",
       "      <td>insightful</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6595</th>\n",
       "      <td>provocative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3521</th>\n",
       "      <td>newborn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9238</th>\n",
       "      <td>verbalize</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9239 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  count\n",
       "8             the   8279\n",
       "15            and   3039\n",
       "54           that   2018\n",
       "119          have   1448\n",
       "4             for   1403\n",
       "...           ...    ...\n",
       "3522  bloodstream      1\n",
       "6594   insightful      1\n",
       "6595  provocative      1\n",
       "3521      newborn      1\n",
       "9238    verbalize      1\n",
       "\n",
       "[9239 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 转置，导入pandas 进行分析\n",
    "df=pd.DataFrame([dicts]).T\n",
    "df=df.reset_index().rename(columns={'index':'word',0:'count'})\n",
    "df.sort_values(by=\"count\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>american</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>economic</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>researcher</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>federal</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199</th>\n",
       "      <td>don</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5131</th>\n",
       "      <td>attorney</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5132</th>\n",
       "      <td>homebuying</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5134</th>\n",
       "      <td>hampson</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5139</th>\n",
       "      <td>purchasing</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480</th>\n",
       "      <td>significantly</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               word  count\n",
       "560        american    116\n",
       "533        economic    102\n",
       "1032     researcher     83\n",
       "2594        federal     79\n",
       "1199            don     76\n",
       "...             ...    ...\n",
       "5131       attorney      3\n",
       "5132     homebuying      3\n",
       "5134        hampson      3\n",
       "5139     purchasing      3\n",
       "3480  significantly      3\n",
       "\n",
       "[1999 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 导入高中单词\n",
    "with open('data/highSchoolWords.csv', 'r', encoding='utf-8') as f:\n",
    "    content = f.read().lower()\n",
    "result = re.findall(r\"(?:^|(?:\\n))(\\w+)\",content)\n",
    "highSchoolWords = pd.DataFrame(result,columns=[\"word\"])\n",
    "\n",
    "\n",
    "# 过滤 属于高中的单词 （ ～ 代表非）\n",
    "data = df[~df.word.isin(highSchoolWords.word)]\n",
    "\n",
    "# 查找词频大于50的单词并按降序排序\n",
    "d = data.query(\"count >=3\").sort_values(by=\"count\", ascending=False)\n",
    "# 保存单词\n",
    "d[\"word\"].to_csv(\"words.csv\",index=0)\n",
    "\n",
    "print(d.shape)\n",
    "d\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
